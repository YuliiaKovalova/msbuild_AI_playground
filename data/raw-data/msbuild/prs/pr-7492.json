{
  "number": 7492,
  "title": "LoggingService log contention",
  "body": "Fixes #7364 \r\n\r\n### Context\r\n[](https://user-images.githubusercontent.com/25249058/152361351-ff5d51a9-5630-4aaf-8178-4597d5bf9773.png)LoggingService.LogComment causes large amounts of contention between unrelated evaluation threads.\r\nimage\r\n\r\n### Changes Made\r\n- Reducing lock statements\r\n  - using Interlock.Add as oppose to lock { n+=x; }\r\n  - replace `Dictionary` with `ConcurrentDictionary` and remove related `lock`s\r\n  - review  `lock`s and remove unnecessary\r\n- Replacing `DataFlow` by `ConcurrentQueue` for event processing\r\n- Fixing unit tests\r\n\r\n### Testing\r\n- local run unit testst\r\n- micro benchmark comparing `DataFlow` by `ConcurrentQueue`\r\n- exp insertion - currently failing on infrastructure - will update\r\n- Compiled Boost.Hana as described in #3577 - no OOM exception\r\n\r\n### Notes\r\nIt has surprisingly good perf results. Maybe because I tested it on 24 core machine where lock contention in LoggingService could be a bigger issue.\r\n\r\n|command|Duration|RAM|\r\n|-|-|-|\r\n|`msbuild /m /bl OrchardCore.sln`|-25%|-4%|\r\n|`msbuild /m OrchardCore.sln`|-13%|-3%|\r\n\r\nMicrobenchmark comparing DataFlow vs ConcurrentQueue processing 1E6 messages showed ~2 seconds  saving (-85%) and about ~250MB allocations less (-92%). I was also considering to use `BlockingCollection` but for this we do not have support in net3.5 and also I have seen weird huge perf degradation for my use case in `net472`.\r\n\r\n|Method|Mean|Allocated|\r\n|-|-:|-:|\r\n|DataFlow| 2,558,860.6 us |  297,286,352 B |\r\n|CocurrentQueue| 371,877.9 us | 26,304,552 B |\r\n\r\n",
  "state": "MERGED",
  "createdAt": "2022-03-28T08:36:52Z",
  "updatedAt": "2022-04-26T13:57:12Z",
  "closedAt": "2022-04-26T13:57:12Z",
  "mergedAt": "2022-04-26T13:57:11Z",
  "additions": 536,
  "deletions": 592,
  "changedFiles": 7,
  "headRefName": "rokonec/7364-LogComment-log-contention",
  "isDraft": false,
  "author": {
    "login": "rokonec"
  },
  "milestone": null,
  "assignees": {
    "nodes": [
      {
        "login": "rainersigwald"
      }
    ]
  },
  "labels": [
    "merge-when-branch-open"
  ],
  "commits": {
    "nodes": [
      {
        "commit": {
          "oid": "fb9da8a7c42fb89af17a1185933411027760dbea",
          "message": "Using Interlock.Add as oppose to lock",
          "committedDate": "2022-03-24T13:25:56Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "d2b45288dc28f82d6a531aa0b1a4fa56037bb130",
          "message": "Replacing DataFlow by ConcurrentQueue",
          "committedDate": "2022-03-24T13:25:56Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "03d14271836030adfa354f210226efbbec9e4cd6",
          "message": "Reducing lock statements in LoggingService",
          "committedDate": "2022-03-24T13:25:56Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "1fb5a3f36a074c1f08e6917181bf74035e692256",
          "message": "Project collection to use asynchronous logging",
          "committedDate": "2022-03-24T13:25:56Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "c70e7148c3273400ecd839f76a06ca6ed8239ac8",
          "message": "Return back sync logging as default for ProjectCollection.",
          "committedDate": "2022-03-24T13:25:56Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "0a8bfb1f4e72616a9e3615869a8ba69312d9ea13",
          "message": "Improve async logging in LoggingService",
          "committedDate": "2022-03-24T13:25:56Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "3b4abda31cc25d9d586b6f639b6c2a26c918b366",
          "message": "FIxing intelocked increment race conditions.",
          "committedDate": "2022-03-24T16:28:34Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "89e9b0b62d276a6fa4fabd664331813bd523c96b",
          "message": "Change pump from task to thread\n-  because of VS issues with thread scheduler",
          "committedDate": "2022-03-25T14:48:53Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "72c5bc7597561bbd9b5d222e31a3782450aa3d75",
          "message": "Fixing unit tests",
          "committedDate": "2022-03-25T22:45:14Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "1c7cddd7c14dad714a9a6e38d904b75d70811491",
          "message": "Dispose in race condition when factoring GlobalProjectCollection",
          "committedDate": "2022-03-28T07:59:43Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "eae89e7a99a5f7dfe21fd84e288364cd7dec0395",
          "message": "Make GlobalProjectCollection async.",
          "committedDate": "2022-03-30T12:30:44Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "f773ae3ada7b8af53d67ce5634603e47dcaf89c9",
          "message": "Fix unit test",
          "committedDate": "2022-03-30T15:49:35Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "ac8de8d149ed1e43968d7817c86cd33a210215c7",
          "message": "Changing to ManulResetSlims for both performance and code logic reason.",
          "committedDate": "2022-04-01T18:13:11Z",
          "author": {
            "name": "Roman Konecny",
            "email": "rokonecn@microsoft.com"
          }
        }
      }
    ]
  },
  "comments": {
    "nodes": [
      {
        "body": "Tagging @lifengl and @arkalyanms who may be interested in the Dataflow performance analysis here.",
        "createdAt": "2022-03-29T01:27:41Z",
        "author": {
          "login": "drewnoakes"
        }
      },
      {
        "body": "@rokonec Will the changes to the logger change timing on the evaluation messages for VS? ",
        "createdAt": "2022-03-29T17:51:41Z",
        "author": {
          "login": "arunchndr"
        }
      },
      {
        "body": "> Will the changes to the logger change timing on the evaluation messages for VS?\r\n\r\n@arkalyanms If I understand the meaning of 'timing' here correctly then NO. Evaluation still uses sync message logging, AFAIK, so messages will be delivered to VS in the same order related to end of Evaluation.\r\nHowever, I'd like if we could discuss, at some point, how VS uses evaluations, and change it into async logging as that could have quite a perf gain for VS concurrent evaluations scenarios.\r\nThat being said, I have changed  logging mode of `GlobalProjectCollection` to async and if VS uses this for evaluation than answer is yes, timing of messages of evaluation could be altered, and messages could be delivered to VS way after evaluations ends.",
        "createdAt": "2022-03-29T19:10:17Z",
        "author": {
          "login": "rokonec"
        }
      },
      {
        "body": "MSBuild evaluates the projects inside the [constructor](https://devdiv.visualstudio.com/DevDiv/_git/CPS?path=/src/Microsoft.VisualStudio.ProjectSystem.Implementation/Projects/ConfiguredProjectImpl.cs&version=GBmain&line=784&lineEnd=784&lineStartColumn=43&lineEndColumn=81&lineStyle=plain&_a=contents), which makes it difficult to bind an evaluation and its artifacts to the new project as a part of the evaluation. So in a backfill step, CPS captures evaluations for unknown projects matching the project path and binds to it after the construction. Evalution messages are no different and we use those to determine if user needs to receive actionable info bars to check the SDK or reload solutions in case of evaluation errors. I wonder in a concurrent evaluation environment it's now possible to lose/ask too early for the error message from the message factory, after the evaluation.\r\n\r\nThis may be a non concern if the logger factory creations are bound internally to an evaluation in queue and wait for the corresponding message logger to arrive. If not, should be done so. @lifengl would you know if this will require a design change on our end?",
        "createdAt": "2022-03-29T19:45:58Z",
        "author": {
          "login": "arunchndr"
        }
      },
      {
        "body": "> This looks great but I'm not confident I understand the ManualResetEvent flow. Could you expand on that a bit?\r\n\r\nI have had version using `_dequeueEvent` and `_enqueueEvent` as AutoResetEvent, but when micro benchmarking, `ManualResetEventSlim` have measurable difference, while not introducing much more complexity (just calling `Reset` after `Wait` just like `AutoResetEvent` \"do\").\r\n\r\n`_emptyQueueEvent` has to be manual event in current logic because it is tested multiple time. Its meaning is actually `in set state while not-in-deque-aka-processing-loop`.\r\n\r\n",
        "createdAt": "2022-04-22T19:09:31Z",
        "author": {
          "login": "rokonec"
        }
      }
    ]
  },
  "reviewThreads": {
    "nodes": [
      {
        "comments": {
          "nodes": [
            {
              "body": "I appreciate making this internal\u2014I get sad when we have tons of constructors that each differ by having one extra parameter, but we need to keep them all exactly as they are to avoid breaking anyone.",
              "createdAt": "2022-03-30T16:48:05Z",
              "path": "src/Build/Definition/ProjectCollection.cs",
              "diffHunk": "@@ -302,6 +308,27 @@ public ProjectCollection(IDictionary<string, string> globalProperties, IEnumerab\n         /// <param name=\"onlyLogCriticalEvents\">If set to true, only critical events will be logged.</param>\n         /// <param name=\"loadProjectsReadOnly\">If set to true, load all projects as read-only.</param>\n         public ProjectCollection(IDictionary<string, string> globalProperties, IEnumerable<ILogger> loggers, IEnumerable<ForwardingLoggerRecord> remoteLoggers, ToolsetDefinitionLocations toolsetDefinitionLocations, int maxNodeCount, bool onlyLogCriticalEvents, bool loadProjectsReadOnly)\n+            : this(globalProperties, loggers, remoteLoggers, toolsetDefinitionLocations, maxNodeCount, onlyLogCriticalEvents, loadProjectsReadOnly, useAsynchronousLogging: false)\n+        {\n+        }\n+\n+\n+        /// <summary>\n+        /// Instantiates a project collection with specified global properties and loggers and using the\n+        /// specified toolset locations, node count, and setting of onlyLogCriticalEvents.\n+        /// Global properties and loggers may be null.\n+        /// Throws InvalidProjectFileException if any of the global properties are reserved.\n+        /// May throw InvalidToolsetDefinitionException.\n+        /// </summary>\n+        /// <param name=\"globalProperties\">The default global properties to use. May be null.</param>\n+        /// <param name=\"loggers\">The loggers to register. May be null and specified to any build instead.</param>\n+        /// <param name=\"remoteLoggers\">Any remote loggers to register. May be null and specified to any build instead.</param>\n+        /// <param name=\"toolsetDefinitionLocations\">The locations from which to load toolsets.</param>\n+        /// <param name=\"maxNodeCount\">The maximum number of nodes to use for building.</param>\n+        /// <param name=\"onlyLogCriticalEvents\">If set to true, only critical events will be logged.</param>\n+        /// <param name=\"loadProjectsReadOnly\">If set to true, load all projects as read-only.</param>\n+        /// <param name=\"useAsynchronousLogging\">If set to true, asynchronous logging will be used. <see cref=\"ProjectCollection.Dispose()\"/> has to called to clear resources used by async logging.</param>\n+        internal ProjectCollection(IDictionary<string, string> globalProperties, IEnumerable<ILogger> loggers, IEnumerable<ForwardingLoggerRecord> remoteLoggers, ToolsetDefinitionLocations toolsetDefinitionLocations, int maxNodeCount, bool onlyLogCriticalEvents, bool loadProjectsReadOnly, bool useAsynchronousLogging)",
              "author": {
                "login": "Forgind"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "```suggestion\r\n                        // Other thread beat us to it; dispose of this project collection\r\n```",
              "createdAt": "2022-03-30T16:48:37Z",
              "path": "src/Build/Definition/ProjectCollection.cs",
              "diffHunk": "@@ -418,8 +446,14 @@ public static ProjectCollection GlobalProjectCollection\n                 {\n                     // Take care to ensure that there is never more than one value observed\n                     // from this property even in the case of race conditions while lazily initializing.\n-                    var local = new ProjectCollection();\n-                    Interlocked.CompareExchange(ref s_globalProjectCollection, local, null);\n+                    var local = new ProjectCollection(null, null, null, ToolsetDefinitionLocations.Default,\n+                        maxNodeCount: 1, onlyLogCriticalEvents: false, loadProjectsReadOnly: false, useAsynchronousLogging: true);\n+\n+                    if (Interlocked.CompareExchange(ref s_globalProjectCollection, local, null) != null)\n+                    {\n+                        // Other thread had beat us to it, lets dispose this project collection",
              "author": {
                "login": "Forgind"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "Did you take out not throttling because in practice we were never not throttling?",
              "createdAt": "2022-03-30T16:55:34Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1202,20 +1172,21 @@ public void LogBuildEvent(BuildEventArgs buildEvent)\n         /// In Synchronous mode the event should be routed to the correct sink or logger right away\n         /// </summary>\n         /// <param name=\"buildEvent\">BuildEventArgs to process</param>\n-        /// <param name=\"allowThrottling\"><code>true</code> to allow throttling, otherwise <code>false</code>.</param>\n         /// <exception cref=\"InternalErrorException\">buildEvent is null</exception>\n-        internal virtual void ProcessLoggingEvent(object buildEvent, bool allowThrottling = false)\n+        internal virtual void ProcessLoggingEvent(object buildEvent)\n         {\n             ErrorUtilities.VerifyThrow(buildEvent != null, \"buildEvent is null\");\n             if (_logMode == LoggerMode.Asynchronous)\n             {\n-                // If the queue is at capacity, this call will block - the task returned by SendAsync only completes \n-                // when the message is actually consumed or rejected (permanently) by the buffer.\n-                var task = _loggingQueue.SendAsync(buildEvent);\n-                if (allowThrottling)\n+                // Block until queue is not full.\n+                while (_eventQueue.Count >= _queueCapacity)\n                 {\n-                    task.Wait();\n+                    // Block and wait for dequeue event.",
              "author": {
                "login": "Forgind"
              }
            },
            {
              "body": "If I understand it correctly `BufferBlock.SendAsync` either return completed `Task` or block when its capacity is reached. That `task.Wait` never blocked.\r\nNot throttling is, IMHO, wrong as it has risk of OOM or too big queues with long waiting times anyway. With blocking we implement backpressure and slow down sender if receiver can't keep up with sending rate. So I have changed the code to always block. If people will report some perf degradation, we shall consider to increase queue capacity (throttling threshold).",
              "createdAt": "2022-03-30T17:54:37Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1202,20 +1172,21 @@ public void LogBuildEvent(BuildEventArgs buildEvent)\n         /// In Synchronous mode the event should be routed to the correct sink or logger right away\n         /// </summary>\n         /// <param name=\"buildEvent\">BuildEventArgs to process</param>\n-        /// <param name=\"allowThrottling\"><code>true</code> to allow throttling, otherwise <code>false</code>.</param>\n         /// <exception cref=\"InternalErrorException\">buildEvent is null</exception>\n-        internal virtual void ProcessLoggingEvent(object buildEvent, bool allowThrottling = false)\n+        internal virtual void ProcessLoggingEvent(object buildEvent)\n         {\n             ErrorUtilities.VerifyThrow(buildEvent != null, \"buildEvent is null\");\n             if (_logMode == LoggerMode.Asynchronous)\n             {\n-                // If the queue is at capacity, this call will block - the task returned by SendAsync only completes \n-                // when the message is actually consumed or rejected (permanently) by the buffer.\n-                var task = _loggingQueue.SendAsync(buildEvent);\n-                if (allowThrottling)\n+                // Block until queue is not full.\n+                while (_eventQueue.Count >= _queueCapacity)\n                 {\n-                    task.Wait();\n+                    // Block and wait for dequeue event.",
              "author": {
                "login": "rokonec"
              }
            },
            {
              "body": "Indeed the lack of throttling was the cause of the OOM in #3577. I am very happy to actually have the backpressure system we have allegedly had for a long time. Agreed on the possiblity of queue tuning.",
              "createdAt": "2022-04-22T15:38:48Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1202,20 +1172,21 @@ public void LogBuildEvent(BuildEventArgs buildEvent)\n         /// In Synchronous mode the event should be routed to the correct sink or logger right away\n         /// </summary>\n         /// <param name=\"buildEvent\">BuildEventArgs to process</param>\n-        /// <param name=\"allowThrottling\"><code>true</code> to allow throttling, otherwise <code>false</code>.</param>\n         /// <exception cref=\"InternalErrorException\">buildEvent is null</exception>\n-        internal virtual void ProcessLoggingEvent(object buildEvent, bool allowThrottling = false)\n+        internal virtual void ProcessLoggingEvent(object buildEvent)\n         {\n             ErrorUtilities.VerifyThrow(buildEvent != null, \"buildEvent is null\");\n             if (_logMode == LoggerMode.Asynchronous)\n             {\n-                // If the queue is at capacity, this call will block - the task returned by SendAsync only completes \n-                // when the message is actually consumed or rejected (permanently) by the buffer.\n-                var task = _loggingQueue.SendAsync(buildEvent);\n-                if (allowThrottling)\n+                // Block until queue is not full.\n+                while (_eventQueue.Count >= _queueCapacity)\n                 {\n-                    task.Wait();\n+                    // Block and wait for dequeue event.",
              "author": {
                "login": "rainersigwald"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "Should we have a check for whether _enqueueEvent is set?",
              "createdAt": "2022-03-30T17:10:11Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1202,20 +1172,21 @@ public void LogBuildEvent(BuildEventArgs buildEvent)\n         /// In Synchronous mode the event should be routed to the correct sink or logger right away\n         /// </summary>\n         /// <param name=\"buildEvent\">BuildEventArgs to process</param>\n-        /// <param name=\"allowThrottling\"><code>true</code> to allow throttling, otherwise <code>false</code>.</param>\n         /// <exception cref=\"InternalErrorException\">buildEvent is null</exception>\n-        internal virtual void ProcessLoggingEvent(object buildEvent, bool allowThrottling = false)\n+        internal virtual void ProcessLoggingEvent(object buildEvent)\n         {\n             ErrorUtilities.VerifyThrow(buildEvent != null, \"buildEvent is null\");\n             if (_logMode == LoggerMode.Asynchronous)\n             {\n-                // If the queue is at capacity, this call will block - the task returned by SendAsync only completes \n-                // when the message is actually consumed or rejected (permanently) by the buffer.\n-                var task = _loggingQueue.SendAsync(buildEvent);\n-                if (allowThrottling)\n+                // Block until queue is not full.\n+                while (_eventQueue.Count >= _queueCapacity)",
              "author": {
                "login": "Forgind"
              }
            },
            {
              "body": "Only role of `_enqueueEvent` is to unblock pumping thread when new message arrives.\r\nIt is perfectly safe to set `AutoResetEvent` which is already in set state.\r\nThere is race condition by design and when it happens pumping thread will do one unnecessary empty loop which has negligible perf cost.",
              "createdAt": "2022-03-30T18:13:47Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1202,20 +1172,21 @@ public void LogBuildEvent(BuildEventArgs buildEvent)\n         /// In Synchronous mode the event should be routed to the correct sink or logger right away\n         /// </summary>\n         /// <param name=\"buildEvent\">BuildEventArgs to process</param>\n-        /// <param name=\"allowThrottling\"><code>true</code> to allow throttling, otherwise <code>false</code>.</param>\n         /// <exception cref=\"InternalErrorException\">buildEvent is null</exception>\n-        internal virtual void ProcessLoggingEvent(object buildEvent, bool allowThrottling = false)\n+        internal virtual void ProcessLoggingEvent(object buildEvent)\n         {\n             ErrorUtilities.VerifyThrow(buildEvent != null, \"buildEvent is null\");\n             if (_logMode == LoggerMode.Asynchronous)\n             {\n-                // If the queue is at capacity, this call will block - the task returned by SendAsync only completes \n-                // when the message is actually consumed or rejected (permanently) by the buffer.\n-                var task = _loggingQueue.SendAsync(buildEvent);\n-                if (allowThrottling)\n+                // Block until queue is not full.\n+                while (_eventQueue.Count >= _queueCapacity)",
              "author": {
                "login": "rokonec"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "If you have multiple competing TryPeeks, that would mean you could process a single event twice, right? Should this be:\r\n```suggestion\r\n                   if (_eventQueue.TryDequeue(out object ev) {\r\n                        LoggingEventProcessor(ev);\r\n                        _dequeueEvent.Set();\r\n                    }\r\n```\r\n\r\n?",
              "createdAt": "2022-03-30T17:15:30Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1305,55 +1252,77 @@ private static int GetWarningsAsErrorOrMessageKey(BuildEventArgs buildEventArgs)\n         }\n \n         /// <summary>\n-        /// Create a logging thread to process the logging queue\n+        /// Create a logging thread to process the logging queue.\n         /// </summary>\n-        private void CreateLoggingEventQueue()\n+        private void StartLoggingEventProcessing()\n         {\n-            // We are creating a two-node dataflow graph here.  The first node is a buffer, which will hold up to the number of\n-            // logging events we have specified as the queueCapacity.  The second node is the processor which will actually process each message.\n-            // When the capacity of the buffer is reached, further attempts to send messages to it will block.\n-            // The reason we can't just set the BoundedCapacity on the processing block is that ActionBlock has some weird behavior\n-            // when the queue capacity is reached.  Specifically, it will block new messages from being processed until it has\n-            // entirely drained its input queue, as opposed to letting new ones in as old ones are processed.  This is logged as \n-            // a perf bug (305575) against Dataflow.  If they choose to fix it, we can eliminate the buffer node from the graph.\n-            var dataBlockOptions = new DataflowBlockOptions\n-            {\n-                BoundedCapacity = Convert.ToInt32(_queueCapacity)\n-            };\n-\n-            var loggingQueue = new BufferBlock<object>(dataBlockOptions);\n-\n-            var executionDataBlockOptions = new ExecutionDataflowBlockOptions\n+            _eventQueue = new ConcurrentQueue<object>();\n+            _dequeueEvent = new AutoResetEvent(false);\n+            _emptyQueueEvent = new AutoResetEvent(false);\n+            _enqueueEvent = new AutoResetEvent(false);\n+            _loggingEventProcessingCancellation = new CancellationTokenSource();\n+\n+            _loggingEventProcessingThread = new Thread(LoggingEventProc);\n+            _loggingEventProcessingThread.Name = $\"MSBuild LoggingService events queue pump: {this.GetHashCode()}\";\n+            _loggingEventProcessingThread.IsBackground = true;\n+            _loggingEventProcessingThread.Start();\n+\n+            void LoggingEventProc()\n             {\n-                BoundedCapacity = 1\n-            };\n-\n-            var loggingQueueProcessor = new ActionBlock<object>(loggingEvent => LoggingEventProcessor(loggingEvent), executionDataBlockOptions);\n+                var completeAdding = _loggingEventProcessingCancellation.Token;\n \n-            var dataLinkOptions = new DataflowLinkOptions\n-            {\n-                PropagateCompletion = true\n-            };\n+                do\n+                {\n+                    // We peak message first in order to not have _eventQueue.IsEmpty before we actually process event\n+                    //   as this could be interpreted like \"every message has been already processed\" otherwise.\n+                    if (_eventQueue.TryPeek(out object ev))\n+                    {\n+                        LoggingEventProcessor(ev);\n+                        _eventQueue.TryDequeue(out _);\n+                        _dequeueEvent.Set();\n+                    }",
              "author": {
                "login": "Forgind"
              }
            },
            {
              "body": "That is true. But we don't have multiple competing `TryPeek` and chance we will need it in future is slim to none.\r\nAs stated in comment, with `TryPeek; process even;, Dequeue;` wee achieve that queue is empty only after all messages has been processed by listeners/loggers.\r\nMethod `WaitForLoggingToProcessEvents` is used in places where logic requires all messages to be fully handled before continue and its implementation consider job to be done when `queue.IsEmpty`.\r\n",
              "createdAt": "2022-03-30T18:02:28Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1305,55 +1252,77 @@ private static int GetWarningsAsErrorOrMessageKey(BuildEventArgs buildEventArgs)\n         }\n \n         /// <summary>\n-        /// Create a logging thread to process the logging queue\n+        /// Create a logging thread to process the logging queue.\n         /// </summary>\n-        private void CreateLoggingEventQueue()\n+        private void StartLoggingEventProcessing()\n         {\n-            // We are creating a two-node dataflow graph here.  The first node is a buffer, which will hold up to the number of\n-            // logging events we have specified as the queueCapacity.  The second node is the processor which will actually process each message.\n-            // When the capacity of the buffer is reached, further attempts to send messages to it will block.\n-            // The reason we can't just set the BoundedCapacity on the processing block is that ActionBlock has some weird behavior\n-            // when the queue capacity is reached.  Specifically, it will block new messages from being processed until it has\n-            // entirely drained its input queue, as opposed to letting new ones in as old ones are processed.  This is logged as \n-            // a perf bug (305575) against Dataflow.  If they choose to fix it, we can eliminate the buffer node from the graph.\n-            var dataBlockOptions = new DataflowBlockOptions\n-            {\n-                BoundedCapacity = Convert.ToInt32(_queueCapacity)\n-            };\n-\n-            var loggingQueue = new BufferBlock<object>(dataBlockOptions);\n-\n-            var executionDataBlockOptions = new ExecutionDataflowBlockOptions\n+            _eventQueue = new ConcurrentQueue<object>();\n+            _dequeueEvent = new AutoResetEvent(false);\n+            _emptyQueueEvent = new AutoResetEvent(false);\n+            _enqueueEvent = new AutoResetEvent(false);\n+            _loggingEventProcessingCancellation = new CancellationTokenSource();\n+\n+            _loggingEventProcessingThread = new Thread(LoggingEventProc);\n+            _loggingEventProcessingThread.Name = $\"MSBuild LoggingService events queue pump: {this.GetHashCode()}\";\n+            _loggingEventProcessingThread.IsBackground = true;\n+            _loggingEventProcessingThread.Start();\n+\n+            void LoggingEventProc()\n             {\n-                BoundedCapacity = 1\n-            };\n-\n-            var loggingQueueProcessor = new ActionBlock<object>(loggingEvent => LoggingEventProcessor(loggingEvent), executionDataBlockOptions);\n+                var completeAdding = _loggingEventProcessingCancellation.Token;\n \n-            var dataLinkOptions = new DataflowLinkOptions\n-            {\n-                PropagateCompletion = true\n-            };\n+                do\n+                {\n+                    // We peak message first in order to not have _eventQueue.IsEmpty before we actually process event\n+                    //   as this could be interpreted like \"every message has been already processed\" otherwise.\n+                    if (_eventQueue.TryPeek(out object ev))\n+                    {\n+                        LoggingEventProcessor(ev);\n+                        _eventQueue.TryDequeue(out _);\n+                        _dequeueEvent.Set();\n+                    }",
              "author": {
                "login": "rokonec"
              }
            },
            {
              "body": "Ok; I think that makes sense.",
              "createdAt": "2022-03-30T20:47:27Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1305,55 +1252,77 @@ private static int GetWarningsAsErrorOrMessageKey(BuildEventArgs buildEventArgs)\n         }\n \n         /// <summary>\n-        /// Create a logging thread to process the logging queue\n+        /// Create a logging thread to process the logging queue.\n         /// </summary>\n-        private void CreateLoggingEventQueue()\n+        private void StartLoggingEventProcessing()\n         {\n-            // We are creating a two-node dataflow graph here.  The first node is a buffer, which will hold up to the number of\n-            // logging events we have specified as the queueCapacity.  The second node is the processor which will actually process each message.\n-            // When the capacity of the buffer is reached, further attempts to send messages to it will block.\n-            // The reason we can't just set the BoundedCapacity on the processing block is that ActionBlock has some weird behavior\n-            // when the queue capacity is reached.  Specifically, it will block new messages from being processed until it has\n-            // entirely drained its input queue, as opposed to letting new ones in as old ones are processed.  This is logged as \n-            // a perf bug (305575) against Dataflow.  If they choose to fix it, we can eliminate the buffer node from the graph.\n-            var dataBlockOptions = new DataflowBlockOptions\n-            {\n-                BoundedCapacity = Convert.ToInt32(_queueCapacity)\n-            };\n-\n-            var loggingQueue = new BufferBlock<object>(dataBlockOptions);\n-\n-            var executionDataBlockOptions = new ExecutionDataflowBlockOptions\n+            _eventQueue = new ConcurrentQueue<object>();\n+            _dequeueEvent = new AutoResetEvent(false);\n+            _emptyQueueEvent = new AutoResetEvent(false);\n+            _enqueueEvent = new AutoResetEvent(false);\n+            _loggingEventProcessingCancellation = new CancellationTokenSource();\n+\n+            _loggingEventProcessingThread = new Thread(LoggingEventProc);\n+            _loggingEventProcessingThread.Name = $\"MSBuild LoggingService events queue pump: {this.GetHashCode()}\";\n+            _loggingEventProcessingThread.IsBackground = true;\n+            _loggingEventProcessingThread.Start();\n+\n+            void LoggingEventProc()\n             {\n-                BoundedCapacity = 1\n-            };\n-\n-            var loggingQueueProcessor = new ActionBlock<object>(loggingEvent => LoggingEventProcessor(loggingEvent), executionDataBlockOptions);\n+                var completeAdding = _loggingEventProcessingCancellation.Token;\n \n-            var dataLinkOptions = new DataflowLinkOptions\n-            {\n-                PropagateCompletion = true\n-            };\n+                do\n+                {\n+                    // We peak message first in order to not have _eventQueue.IsEmpty before we actually process event\n+                    //   as this could be interpreted like \"every message has been already processed\" otherwise.\n+                    if (_eventQueue.TryPeek(out object ev))\n+                    {\n+                        LoggingEventProcessor(ev);\n+                        _eventQueue.TryDequeue(out _);\n+                        _dequeueEvent.Set();\n+                    }",
              "author": {
                "login": "Forgind"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "I'm not sure I understand how this avoids a race. Can you elaborate a bit?",
              "createdAt": "2022-04-22T15:42:32Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1227,41 +1202,21 @@ internal virtual void ProcessLoggingEvent(object buildEvent, bool allowThrottlin\n         }\n \n         /// <summary>\n-        /// Wait for the logging messages in the logging queue to be completly processed.\n+        /// Wait for the logging messages in the logging queue to be completely processed.\n         /// This is required because for Logging build finished or when the component is to shutdown\n         /// we need to make sure we process all of the events before the build finished event is raised\n         /// and we need to make sure we process all of the logging events before we shutdown the component.\n         /// </summary>\n-        internal void WaitForThreadToProcessEvents()\n+        public void WaitForLoggingToProcessEvents()\n         {\n-            // This method may be called in the shutdown submission callback, this callback may be called after the logging service has \n-            // shutdown and nulled out the events we were going to wait on.\n-            if (_logMode == LoggerMode.Asynchronous && _loggingQueue != null)\n+            while (_eventQueue?.IsEmpty == false)\n             {\n-                BufferBlock<object> loggingQueue = null;\n-                ActionBlock<object> loggingQueueProcessor = null;\n-\n-                lock (_lockObject)\n-                {\n-                    loggingQueue = _loggingQueue;\n-                    loggingQueueProcessor = _loggingQueueProcessor;\n-\n-                    // Replaces _loggingQueue and _loggingQueueProcessor with new one, this will assure that\n-                    // no further messages could possibly be trying to be added into queue we are about to drain\n-                    CreateLoggingEventQueue();\n-                }\n-\n-                // Drain queue.\n-                // This shall not be locked to avoid possible deadlock caused by\n-                // event handlers to reenter 'this' instance while trying to log something.\n-                if (loggingQueue != null)\n-                {\n-                    Debug.Assert(!Monitor.IsEntered(_lockObject));\n-\n-                    loggingQueue.Complete();\n-                    loggingQueueProcessor.Completion.Wait();\n-                }\n+                _emptyQueueEvent?.Wait();\n             }\n+            // To avoid race condition when last message has been removed from queue but\n+            //   not yet fully processed (handled by loggers), we need to make sure _emptyQueueEvent\n+            //   is set as it is guaranteed to be in set state no sooner than after event has been processed.\n+            _emptyQueueEvent?.Wait();",
              "author": {
                "login": "rainersigwald"
              }
            },
            {
              "body": "Lets suppose `WaitForLoggingToProcessEvents` is called right at the time another thread is processing last message from queue `LoggingEventProcessor(ev);` at line 1287. At this time queue is already empty and without line 1219 `_emptyQueueEvent?.Wait();` method `WaitForLoggingToProcessEvents` would ends immediately event though the last message from queue is still processing.\r\nBecause `_emptyQueueEvent` is never in set state while message is processing but will enter set state after last message from queue is processed this line fixes above race condition bug.\r\n\r\nProbability of this race condition is very small, however there is a unit test which were consistently failing on this RC.\r\n",
              "createdAt": "2022-04-22T18:48:50Z",
              "path": "src/Build/BackEnd/Components/Logging/LoggingService.cs",
              "diffHunk": "@@ -1227,41 +1202,21 @@ internal virtual void ProcessLoggingEvent(object buildEvent, bool allowThrottlin\n         }\n \n         /// <summary>\n-        /// Wait for the logging messages in the logging queue to be completly processed.\n+        /// Wait for the logging messages in the logging queue to be completely processed.\n         /// This is required because for Logging build finished or when the component is to shutdown\n         /// we need to make sure we process all of the events before the build finished event is raised\n         /// and we need to make sure we process all of the logging events before we shutdown the component.\n         /// </summary>\n-        internal void WaitForThreadToProcessEvents()\n+        public void WaitForLoggingToProcessEvents()\n         {\n-            // This method may be called in the shutdown submission callback, this callback may be called after the logging service has \n-            // shutdown and nulled out the events we were going to wait on.\n-            if (_logMode == LoggerMode.Asynchronous && _loggingQueue != null)\n+            while (_eventQueue?.IsEmpty == false)\n             {\n-                BufferBlock<object> loggingQueue = null;\n-                ActionBlock<object> loggingQueueProcessor = null;\n-\n-                lock (_lockObject)\n-                {\n-                    loggingQueue = _loggingQueue;\n-                    loggingQueueProcessor = _loggingQueueProcessor;\n-\n-                    // Replaces _loggingQueue and _loggingQueueProcessor with new one, this will assure that\n-                    // no further messages could possibly be trying to be added into queue we are about to drain\n-                    CreateLoggingEventQueue();\n-                }\n-\n-                // Drain queue.\n-                // This shall not be locked to avoid possible deadlock caused by\n-                // event handlers to reenter 'this' instance while trying to log something.\n-                if (loggingQueue != null)\n-                {\n-                    Debug.Assert(!Monitor.IsEntered(_lockObject));\n-\n-                    loggingQueue.Complete();\n-                    loggingQueueProcessor.Completion.Wait();\n-                }\n+                _emptyQueueEvent?.Wait();\n             }\n+            // To avoid race condition when last message has been removed from queue but\n+            //   not yet fully processed (handled by loggers), we need to make sure _emptyQueueEvent\n+            //   is set as it is guaranteed to be in set state no sooner than after event has been processed.\n+            _emptyQueueEvent?.Wait();",
              "author": {
                "login": "rokonec"
              }
            }
          ]
        }
      }
    ]
  }
}