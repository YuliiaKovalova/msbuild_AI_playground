{
  "number": 8989,
  "title": "Refresh and update RetrievableEntryHashset",
  "body": "(This is on top of https://github.com/dotnet/msbuild/pull/8986 which should be merged first to make this smaller.)\r\n\r\nSince RetrievableEntryHashSet snapped Hashset code many years ago, numerous improvements have been made to Hashset for size and performance. This brings over those improvements. I compared side by side in a diff/merge tool, and copied pasted as appropriate, re-applying the special changes on the MSBuild side.\r\n\r\nNOTE -- in Hashset, the \"fastmod\" optimization is only used in 64 bit builds. It can do this because it's in corelib, which has separate 32 and 64 bit builds. MSBuild of course does not, so I used this path in both bitnesses. It may be a slight deoptimization for lookups when running in a 32 bit process, hopefully outweighed by the improvement in 64 bit which is much more common.\r\n\r\nThis ought to be measured for performance -- is there a magic way to do that before/after?",
  "state": "CLOSED",
  "createdAt": "2023-07-02T05:13:27Z",
  "updatedAt": "2023-07-02T17:17:10Z",
  "closedAt": "2023-07-02T17:17:09Z",
  "mergedAt": null,
  "additions": 792,
  "deletions": 3287,
  "changedFiles": 36,
  "headRefName": "improvehashset",
  "isDraft": false,
  "author": {
    "login": "danmoseley"
  },
  "milestone": null,
  "assignees": {
    "nodes": []
  },
  "labels": [],
  "commits": {
    "nodes": [
      {
        "commit": {
          "oid": "a293a5d6036313b6cb36eb6670eac7880b697e6d",
          "message": "remove ifnever",
          "committedDate": "2023-06-30T23:25:39Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "793f68b0867808b118d3ca3d8ad5e769dbc8d0ff",
          "message": "more",
          "committedDate": "2023-06-30T23:28:54Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "103b4df4e4a4502590058dd578a5d090b0b951c1",
          "message": "improve hashset",
          "committedDate": "2023-07-02T02:37:51Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "bd49a53ef536c4432fbca66af76f9e0dc793f817",
          "message": "cleanup",
          "committedDate": "2023-07-02T05:10:25Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "f9133a8abb794b260eb002b61d6edabc8d4944d6",
          "message": "extra file",
          "committedDate": "2023-07-02T05:15:07Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "7b68241dad77fd7b28fe9567401ebaa90f00bd61",
          "message": "remove constrained comparer",
          "committedDate": "2023-07-02T05:34:04Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "91c654b95ba2f531bbe7ad0376aadc5d5549d648",
          "message": "drop const field",
          "committedDate": "2023-07-02T05:37:12Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "2b461386406245dacdc8419a37fdad8c6fdfa41a",
          "message": "revert ex",
          "committedDate": "2023-07-02T05:47:53Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "8b56f2a55459103d1dc3f0de30702a8c2378cd90",
          "message": "remove nullable annot",
          "committedDate": "2023-07-02T05:49:48Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "edea820dd9b1e120168496f1047ec71f2312f691",
          "message": "remove version",
          "committedDate": "2023-07-02T06:22:07Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "e043bcd8ddc65025bb9fe3ac135cab1a24420196",
          "message": "build break",
          "committedDate": "2023-07-02T14:05:07Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "b9b7df94e2c808978660eb63c08911a2b393aece",
          "message": "assert",
          "committedDate": "2023-07-02T15:25:47Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "e6b01e3ba7d6cec14c083138708af6deae0ec589",
          "message": "fix longstanding bug",
          "committedDate": "2023-07-02T15:31:30Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "205f1682baf40162bad34c42419efc1eec370882",
          "message": "bug",
          "committedDate": "2023-07-02T15:52:13Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "ca376abe5f70e6486ad99fe1448934ba8c4bbcaf",
          "message": "bug",
          "committedDate": "2023-07-02T15:58:07Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "3106365ebced313842ac4ce48b34dea09a2767f5",
          "message": "bug",
          "committedDate": "2023-07-02T16:01:58Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "1d6de361fd954455fd47c1373a7659ba71b432cf",
          "message": "bug",
          "committedDate": "2023-07-02T16:07:28Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "fe2eee75db0ce2c71c729571fea6d3808dcb1e04",
          "message": "more missing res",
          "committedDate": "2023-07-02T16:24:30Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "b606f977ad2d67b82e6ffe9abd042558823b9616",
          "message": "xlf",
          "committedDate": "2023-07-02T16:26:55Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "684f5a452c83ba494f22df17d00e322095f93f1c",
          "message": "more missing res",
          "committedDate": "2023-07-02T16:34:21Z",
          "author": {
            "name": "Dan Moseley",
            "email": "danmose@microsoft.com"
          }
        }
      }
    ]
  },
  "comments": {
    "nodes": [
      {
        "body": "I'm going to break this into smaller PR's.",
        "createdAt": "2023-07-02T17:17:09Z",
        "author": {
          "login": "danmoseley"
        }
      }
    ]
  },
  "reviewThreads": {
    "nodes": [
      {
        "comments": {
          "nodes": [
            {
              "body": "from Hashset, untested here. And hopefully going away soon with your use of BinaryFormatter.",
              "createdAt": "2023-07-02T05:15:23Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashHelpers.SerializationInfoTable.cs",
              "diffHunk": "@@ -0,0 +1,29 @@\n+// Licensed to the .NET Foundation under one or more agreements.",
              "author": {
                "login": "danmoseley"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "improved method name.",
              "createdAt": "2023-07-02T05:15:55Z",
              "path": "src/Build/Definition/Project.cs",
              "diffHunk": "@@ -4421,7 +4421,7 @@ public IItemDefinition<ProjectMetadata> AddItemDefinition(string itemType)\n             {\n                 ProjectItemDefinition newItemDefinition = new ProjectItemDefinition(Project, itemType);\n \n-                ItemDefinitions.Add(newItemDefinition);\n+                ItemDefinitions.AddOrReplace(newItemDefinition);",
              "author": {
                "login": "danmoseley"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "cleaned up this file \r\n1. remove the actual exception throwing from within VerifyThrowXX. this makes it more likely they can inline. \"outside\" the condition is hot.\r\n2. add string resource verify to just outside every condition, and only there. inside the condition, it's going to try to load it anyway.\r\n3. move s_throwExceptions inside the cold ThrowXX methods as well.",
              "createdAt": "2023-07-02T05:17:58Z",
              "path": "src/Shared/ErrorUtilities.cs",
              "diffHunk": "@@ -52,9 +52,9 @@ public static void DebugTraceMessage(string category, string formatstring, param\n \n         internal static void VerifyThrowInternalError(bool condition, string message, params object[] args)\n         {\n-            if (s_throwExceptions && !condition)\n+            if (!condition)",
              "author": {
                "login": "danmoseley"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "basically verbatim from runtime copy",
              "createdAt": "2023-07-02T05:18:29Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashHelpers.cs",
              "diffHunk": "@@ -1,40 +1,41 @@\n \ufeff// Licensed to the .NET Foundation under one or more agreements.\n // The .NET Foundation licenses this file to you under the MIT license.\n \n-using System;\n using System.Diagnostics;\n-#if !SILVERLIGHT\n-#if FEATURE_CONSTRAINED_EXECUTION\n-using System.Runtime.ConstrainedExecution;\n-#endif\n-#endif\n+using System.Runtime.CompilerServices;",
              "author": {
                "login": "danmoseley"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "difficult to review (will be easier when other PR is merged)\r\n\r\nessentially the dotnet/runtime version, with the MSBuild modifications, unused stuff removed, some style cleanup.\r\n\r\nnote -- we're probably a bit inconsistent about verifythrow vs debug.assert. it might be good at some future point to figure out what is actually exposed publicly. everything else should be debug.assert. and we can probably stub out some of the interface implementations if they're not publicly exposed.",
              "createdAt": "2023-07-02T05:20:44Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashSet.cs",
              "diffHunk": "@@ -1,219 +1,142 @@\n-\ufeff// Licensed to the .NET Foundation under one or more agreements.\n+// Licensed to the .NET Foundation under one or more agreements.",
              "author": {
                "login": "danmoseley"
              }
            },
            {
              "body": "and maybe version can become debug only too.",
              "createdAt": "2023-07-02T05:22:34Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashSet.cs",
              "diffHunk": "@@ -1,219 +1,142 @@\n-\ufeff// Licensed to the .NET Foundation under one or more agreements.\n+// Licensed to the .NET Foundation under one or more agreements.",
              "author": {
                "login": "danmoseley"
              }
            },
            {
              "body": "removed version.",
              "createdAt": "2023-07-02T06:22:26Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashSet.cs",
              "diffHunk": "@@ -1,219 +1,142 @@\n-\ufeff// Licensed to the .NET Foundation under one or more agreements.\n+// Licensed to the .NET Foundation under one or more agreements.",
              "author": {
                "login": "danmoseley"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "adds 8 bytes for the multiplier but removed 4/8 bytes for the constrained comparer, which I think is reasonable to obtain when needed.",
              "createdAt": "2023-07-02T05:35:15Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashSet.cs",
              "diffHunk": "@@ -1,219 +1,140 @@\n-\ufeff// Licensed to the .NET Foundation under one or more agreements.\n+// Licensed to the .NET Foundation under one or more agreements.\n // The .NET Foundation licenses this file to you under the MIT license.\n \n using System;\n using System.Collections;\n using System.Collections.Generic;\n+using System.ComponentModel;\n using System.Diagnostics;\n-using System.Diagnostics.CodeAnalysis;\n-using System.Diagnostics.Contracts;\n+using System.Runtime.CompilerServices;\n using System.Runtime.Serialization;\n-using System.Security;\n-using Microsoft.Build.Internal;\n using Microsoft.Build.Shared;\n \n-/*\n-    ==================================================================================================================\n-    MSBUILD COMMENT:\n-\n-    Ripped off from Hashset.cs with the following changes:\n-\n-    * class renamed\n-    * unnecessary methods and attributes if-deffed out (code retained to help windiff, but indented)\n-    * require T implements IKeyed, and accept IKeyed directly where necessary\n-    * all constructors require a comparer -- an IEqualityComparer<IKeyed> -- to avoid mistakes\n-    * change Contains to give you back the found entry, rather than a boolean\n-    * change Add so that it always adds, even if there's an entry already present with the same name. \n-           We want \"replacement\" semantics, like a dictionary keyed on name.\n-    * constructor that allows the collection to be read-only\n-    * implement IDictionary<string, T>\n-    * some convenience methods taking 'string' as overloads of methods taking IKeyed\n-    \n-    Other than this it is modified absolutely minimally to make it easy to diff with the originals (in the Originals folder) \n-    to verify that no errors were introduced, and make it easier to possibly pick up any future bug fixes to the original. \n-    The care taken to minimally modify this means that it is not necessary to carefully code review this complex class, \n-    nor unit test it directly.\n-    ==================================================================================================================\n-*/\n-\n+// Difficult to make this nullable clean because although it doesn't accept null values,\n+// so IDictionary<string, T> is appropriate, Get() may return them. \n #nullable disable\n \n namespace Microsoft.Build.Collections\n {\n     /// <summary>\n-    /// Implementation notes:\n-    /// This uses an array-based implementation similar to <see cref=\"Dictionary{TKey, TValue}\" />, using a buckets array\n-    /// to map hash values to the Slots array. Items in the Slots array that hash to the same value\n-    /// are chained together through the \"next\" indices. \n-    /// \n-    /// The capacity is always prime; so during resizing, the capacity is chosen as the next prime\n-    /// greater than double the last capacity. \n-    /// \n-    /// The underlying data structures are lazily initialized. Because of the observation that, \n-    /// in practice, hashtables tend to contain only a few elements, the initial capacity is\n-    /// set very small (3 elements) unless the ctor with a collection is used.\n-    /// \n-    /// The +/- 1 modifications in methods that add, check for containment, etc allow us to \n-    /// distinguish a hash code of 0 from an uninitialized bucket. This saves us from having to \n-    /// reset each bucket to -1 when resizing. See Contains, for example.\n-    /// \n-    /// Set methods such as UnionWith, IntersectWith, ExceptWith, and SymmetricExceptWith modify\n-    /// this set.\n-    /// \n-    /// Some operations can perform faster if we can assume \"other\" contains unique elements\n-    /// according to this equality comparer. The only times this is efficient to check is if\n-    /// other is a hashset. Note that checking that it's a hashset alone doesn't suffice; we\n-    /// also have to check that the hashset is using the same equality comparer. If other \n-    /// has a different equality comparer, it will have unique elements according to its own\n-    /// equality comparer, but not necessarily according to ours. Therefore, to go these \n-    /// optimized routes we check that other is a hashset using the same equality comparer.\n-    /// \n-    /// A HashSet with no elements has the properties of the empty set. (See IsSubset, etc. for \n-    /// special empty set checks.)\n-    /// \n-    /// A couple of methods have a special case if other is this (e.g. SymmetricExceptWith). \n-    /// If we didn't have these checks, we could be iterating over the set and modifying at\n-    /// the same time. \n+    ///    A dictionary for entries that know their own keys.\n+    ///    This is the standard Hashset with the following changes:\n+    ///\n+    ///    * require T implements IKeyed, and accept IKeyed directly where necessary\n+    ///    * all constructors require a comparer -- an IEqualityComparer&lt;IKeyed&gt; -- to avoid mistakes\n+    ///    * Get() to give you back the found entry, rather than just Contains() for a boolean\n+    ///    * Add() always adds, even if there's an entry already present with the same name (replacement semantics)\n+    ///    * Can set to read-only.\n+    ///    * implement IDictionary&lt;string, T&gt;\n+    ///    * some convenience methods taking 'string' as overloads of methods taking IKeyed.\n     /// </summary>\n-    /// <typeparam name=\"T\"></typeparam>\n-    [DebuggerTypeProxy(typeof(Microsoft.Build.Collections.HashSetDebugView<>))]\n+    /// <typeparam name=\"T\">The type of the thing, such as a Property.</typeparam>\n+    [DebuggerTypeProxy(typeof(ICollectionDebugView<>))]\n     [DebuggerDisplay(\"Count = {Count}\")]\n-    [SuppressMessage(\"Microsoft.Naming\", \"CA1710:IdentifiersShouldHaveCorrectSuffix\", Justification = \"By design\")]\n-    [Serializable()]\n-#if FEATURE_SECURITY_PERMISSIONS\n-    [System.Security.Permissions.HostProtection(MayLeakOnAbort = true)]\n-#endif\n+    [Serializable]\n     internal class RetrievableEntryHashSet<T> : ICollection<T>,\n         ISerializable, IDeserializationCallback,\n         IDictionary<string, T>\n         where T : class, IKeyed\n     {\n-        // store lower 31 bits of hash code\n-        private const int Lower31BitMask = 0x7FFFFFFF;\n-#if NEVER\n-        // cutoff point, above which we won't do stackallocs. This corresponds to 100 integers.\n-        private const int StackAllocThreshold = 100;\n-#endif\n-        // when constructing a hashset from an existing collection, it may contain duplicates, \n-        // so this is used as the max acceptable excess ratio of capacity to count. Note that\n-        // this is only used on the ctor and not to automatically shrink if the hashset has, e.g,\n-        // a lot of adds followed by removes. Users must explicitly shrink by calling TrimExcess.\n-        // This is set to 3 because capacity is acceptable as 2x rounded up to nearest prime.\n-        private const int ShrinkThreshold = 3;\n+        // This uses the same array-based implementation as Dictionary<TKey, TValue>.\n+\n+        // Constants for serialization\n+        private const string CapacityName = \"Capacity\"; // Do not rename (binary serialization)\n+        private const string ElementsName = \"Elements\"; // Do not rename (binary serialization)\n+        private const string ComparerName = \"Comparer\"; // Do not rename (binary serialization)\n+        private const string VersionName = \"Version\"; // Do not rename (binary serialization)\n \n-        // constants for serialization\n-        private const String CapacityName = \"Capacity\";\n-        private const String ElementsName = \"Elements\";\n-        private const String ComparerName = \"Comparer\";\n-        private const String VersionName = \"Version\";\n+        /// <summary>\n+        /// When constructing a hashset from an existing collection, it may contain duplicates,\n+        /// so this is used as the max acceptable excess ratio of capacity to count. Note that\n+        /// this is only used on the ctor and not to automatically shrink if the hashset has, e.g,\n+        /// a lot of adds followed by removes. Users must explicitly shrink by calling TrimExcess.\n+        /// This is set to 3 because capacity is acceptable as 2x rounded up to nearest prime.\n+        /// </summary>\n+        private const int ShrinkThreshold = 3;\n+        private const int StartOfFreeList = -3;\n \n         private int[] _buckets;\n-        private Slot[] _slots;\n+        private Entry[] _entries;\n+        private ulong _fastModMultiplier;",
              "author": {
                "login": "danmoseley"
              }
            },
            {
              "body": "and now I removed the 4 byte version.",
              "createdAt": "2023-07-02T06:23:00Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashSet.cs",
              "diffHunk": "@@ -1,219 +1,140 @@\n-\ufeff// Licensed to the .NET Foundation under one or more agreements.\n+// Licensed to the .NET Foundation under one or more agreements.\n // The .NET Foundation licenses this file to you under the MIT license.\n \n using System;\n using System.Collections;\n using System.Collections.Generic;\n+using System.ComponentModel;\n using System.Diagnostics;\n-using System.Diagnostics.CodeAnalysis;\n-using System.Diagnostics.Contracts;\n+using System.Runtime.CompilerServices;\n using System.Runtime.Serialization;\n-using System.Security;\n-using Microsoft.Build.Internal;\n using Microsoft.Build.Shared;\n \n-/*\n-    ==================================================================================================================\n-    MSBUILD COMMENT:\n-\n-    Ripped off from Hashset.cs with the following changes:\n-\n-    * class renamed\n-    * unnecessary methods and attributes if-deffed out (code retained to help windiff, but indented)\n-    * require T implements IKeyed, and accept IKeyed directly where necessary\n-    * all constructors require a comparer -- an IEqualityComparer<IKeyed> -- to avoid mistakes\n-    * change Contains to give you back the found entry, rather than a boolean\n-    * change Add so that it always adds, even if there's an entry already present with the same name. \n-           We want \"replacement\" semantics, like a dictionary keyed on name.\n-    * constructor that allows the collection to be read-only\n-    * implement IDictionary<string, T>\n-    * some convenience methods taking 'string' as overloads of methods taking IKeyed\n-    \n-    Other than this it is modified absolutely minimally to make it easy to diff with the originals (in the Originals folder) \n-    to verify that no errors were introduced, and make it easier to possibly pick up any future bug fixes to the original. \n-    The care taken to minimally modify this means that it is not necessary to carefully code review this complex class, \n-    nor unit test it directly.\n-    ==================================================================================================================\n-*/\n-\n+// Difficult to make this nullable clean because although it doesn't accept null values,\n+// so IDictionary<string, T> is appropriate, Get() may return them. \n #nullable disable\n \n namespace Microsoft.Build.Collections\n {\n     /// <summary>\n-    /// Implementation notes:\n-    /// This uses an array-based implementation similar to <see cref=\"Dictionary{TKey, TValue}\" />, using a buckets array\n-    /// to map hash values to the Slots array. Items in the Slots array that hash to the same value\n-    /// are chained together through the \"next\" indices. \n-    /// \n-    /// The capacity is always prime; so during resizing, the capacity is chosen as the next prime\n-    /// greater than double the last capacity. \n-    /// \n-    /// The underlying data structures are lazily initialized. Because of the observation that, \n-    /// in practice, hashtables tend to contain only a few elements, the initial capacity is\n-    /// set very small (3 elements) unless the ctor with a collection is used.\n-    /// \n-    /// The +/- 1 modifications in methods that add, check for containment, etc allow us to \n-    /// distinguish a hash code of 0 from an uninitialized bucket. This saves us from having to \n-    /// reset each bucket to -1 when resizing. See Contains, for example.\n-    /// \n-    /// Set methods such as UnionWith, IntersectWith, ExceptWith, and SymmetricExceptWith modify\n-    /// this set.\n-    /// \n-    /// Some operations can perform faster if we can assume \"other\" contains unique elements\n-    /// according to this equality comparer. The only times this is efficient to check is if\n-    /// other is a hashset. Note that checking that it's a hashset alone doesn't suffice; we\n-    /// also have to check that the hashset is using the same equality comparer. If other \n-    /// has a different equality comparer, it will have unique elements according to its own\n-    /// equality comparer, but not necessarily according to ours. Therefore, to go these \n-    /// optimized routes we check that other is a hashset using the same equality comparer.\n-    /// \n-    /// A HashSet with no elements has the properties of the empty set. (See IsSubset, etc. for \n-    /// special empty set checks.)\n-    /// \n-    /// A couple of methods have a special case if other is this (e.g. SymmetricExceptWith). \n-    /// If we didn't have these checks, we could be iterating over the set and modifying at\n-    /// the same time. \n+    ///    A dictionary for entries that know their own keys.\n+    ///    This is the standard Hashset with the following changes:\n+    ///\n+    ///    * require T implements IKeyed, and accept IKeyed directly where necessary\n+    ///    * all constructors require a comparer -- an IEqualityComparer&lt;IKeyed&gt; -- to avoid mistakes\n+    ///    * Get() to give you back the found entry, rather than just Contains() for a boolean\n+    ///    * Add() always adds, even if there's an entry already present with the same name (replacement semantics)\n+    ///    * Can set to read-only.\n+    ///    * implement IDictionary&lt;string, T&gt;\n+    ///    * some convenience methods taking 'string' as overloads of methods taking IKeyed.\n     /// </summary>\n-    /// <typeparam name=\"T\"></typeparam>\n-    [DebuggerTypeProxy(typeof(Microsoft.Build.Collections.HashSetDebugView<>))]\n+    /// <typeparam name=\"T\">The type of the thing, such as a Property.</typeparam>\n+    [DebuggerTypeProxy(typeof(ICollectionDebugView<>))]\n     [DebuggerDisplay(\"Count = {Count}\")]\n-    [SuppressMessage(\"Microsoft.Naming\", \"CA1710:IdentifiersShouldHaveCorrectSuffix\", Justification = \"By design\")]\n-    [Serializable()]\n-#if FEATURE_SECURITY_PERMISSIONS\n-    [System.Security.Permissions.HostProtection(MayLeakOnAbort = true)]\n-#endif\n+    [Serializable]\n     internal class RetrievableEntryHashSet<T> : ICollection<T>,\n         ISerializable, IDeserializationCallback,\n         IDictionary<string, T>\n         where T : class, IKeyed\n     {\n-        // store lower 31 bits of hash code\n-        private const int Lower31BitMask = 0x7FFFFFFF;\n-#if NEVER\n-        // cutoff point, above which we won't do stackallocs. This corresponds to 100 integers.\n-        private const int StackAllocThreshold = 100;\n-#endif\n-        // when constructing a hashset from an existing collection, it may contain duplicates, \n-        // so this is used as the max acceptable excess ratio of capacity to count. Note that\n-        // this is only used on the ctor and not to automatically shrink if the hashset has, e.g,\n-        // a lot of adds followed by removes. Users must explicitly shrink by calling TrimExcess.\n-        // This is set to 3 because capacity is acceptable as 2x rounded up to nearest prime.\n-        private const int ShrinkThreshold = 3;\n+        // This uses the same array-based implementation as Dictionary<TKey, TValue>.\n+\n+        // Constants for serialization\n+        private const string CapacityName = \"Capacity\"; // Do not rename (binary serialization)\n+        private const string ElementsName = \"Elements\"; // Do not rename (binary serialization)\n+        private const string ComparerName = \"Comparer\"; // Do not rename (binary serialization)\n+        private const string VersionName = \"Version\"; // Do not rename (binary serialization)\n \n-        // constants for serialization\n-        private const String CapacityName = \"Capacity\";\n-        private const String ElementsName = \"Elements\";\n-        private const String ComparerName = \"Comparer\";\n-        private const String VersionName = \"Version\";\n+        /// <summary>\n+        /// When constructing a hashset from an existing collection, it may contain duplicates,\n+        /// so this is used as the max acceptable excess ratio of capacity to count. Note that\n+        /// this is only used on the ctor and not to automatically shrink if the hashset has, e.g,\n+        /// a lot of adds followed by removes. Users must explicitly shrink by calling TrimExcess.\n+        /// This is set to 3 because capacity is acceptable as 2x rounded up to nearest prime.\n+        /// </summary>\n+        private const int ShrinkThreshold = 3;\n+        private const int StartOfFreeList = -3;\n \n         private int[] _buckets;\n-        private Slot[] _slots;\n+        private Entry[] _entries;\n+        private ulong _fastModMultiplier;",
              "author": {
                "login": "danmoseley"
              }
            }
          ]
        }
      },
      {
        "comments": {
          "nodes": [
            {
              "body": "this comment here is what I was referring to. it works on 32 bit, IIRC this is here because on 32 bit the multiply below is less efficient . @stephentoub there's no correctness issue here, right? they don't have the benefit of #if BIT64 in this project. My assumption is that the vast majority of their use is 64 bit.",
              "createdAt": "2023-07-02T05:45:40Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashHelpers.cs",
              "diffHunk": "@@ -46,61 +47,76 @@ internal static bool IsPrime(int candidate)\n                         return false;\n                     }\n                 }\n+\n                 return true;\n             }\n+\n             return candidate == 2;\n         }\n \n-#if !SILVERLIGHT\n-#if FEATURE_CONSTRAINED_EXECUTION\n-        [ReliabilityContract(Consistency.WillNotCorruptState, Cer.Success)]\n-#endif\n-#endif\n-        internal static int GetPrime(int min)\n+        public static int GetPrime(int min)\n         {\n-            Debug.Assert(min >= 0, \"min less than zero; handle overflow checking before calling HashHelpers\");\n+            if (min < 0)\n+            {\n+                throw new ArgumentException();\n+            }\n \n-            for (int i = 0; i < primes.Length; i++)\n+            foreach (int prime in Primes)\n             {\n-                int prime = primes[i];\n                 if (prime >= min)\n                 {\n                     return prime;\n                 }\n             }\n \n-            // Outside of our predefined table. Compute the hard way. \n-            for (int i = (min | 1); i < Int32.MaxValue; i += 2)\n+            // Outside of our predefined table. Compute the hard way.\n+            for (int i = min | 1; i < int.MaxValue; i += 2)\n             {\n-                if (IsPrime(i))\n+                if (IsPrime(i) && ((i - 1) % HashPrime != 0))\n                 {\n                     return i;\n                 }\n             }\n-            return min;\n-        }\n \n-        internal static int GetMinPrime()\n-        {\n-            return primes[0];\n+            return min;\n         }\n \n         // Returns size of hashtable to grow to.\n-        internal static int ExpandPrime(int oldSize)\n+        public static int ExpandPrime(int oldSize)\n         {\n             int newSize = 2 * oldSize;\n \n-            // Allow the hashtables to grow to maximum possible size (~2G elements) before encoutering capacity overflow.\n+            // Allow the hashtables to grow to maximum possible size (~2G elements) before encountering capacity overflow.\n             // Note that this check works even when _items.Length overflowed thanks to the (uint) cast\n-            if ((uint)newSize > MaxPrimeArrayLength)\n+            if ((uint)newSize > MaxPrimeArrayLength && oldSize < MaxPrimeArrayLength)\n             {\n+                Debug.Assert(GetPrime(MaxPrimeArrayLength) == MaxPrimeArrayLength, \"Invalid MaxPrimeArrayLength\");\n                 return MaxPrimeArrayLength;\n             }\n \n             return GetPrime(newSize);\n         }\n \n-        // This is the maximum prime smaller than Array.MaxArrayLength\n-        internal const int MaxPrimeArrayLength = 0x7FEFFFFD;\n+        /// <summary>Returns approximate reciprocal of the divisor: ceil(2**64 / divisor).</summary>\n+        /// <remarks>This should only be used on 64-bit.</remarks>",
              "author": {
                "login": "danmoseley"
              }
            },
            {
              "body": "> there's no correctness issue here, right\r\n\r\nCorrect",
              "createdAt": "2023-07-02T10:24:13Z",
              "path": "src/Build/Collections/RetrievableEntryHashSet/HashHelpers.cs",
              "diffHunk": "@@ -46,61 +47,76 @@ internal static bool IsPrime(int candidate)\n                         return false;\n                     }\n                 }\n+\n                 return true;\n             }\n+\n             return candidate == 2;\n         }\n \n-#if !SILVERLIGHT\n-#if FEATURE_CONSTRAINED_EXECUTION\n-        [ReliabilityContract(Consistency.WillNotCorruptState, Cer.Success)]\n-#endif\n-#endif\n-        internal static int GetPrime(int min)\n+        public static int GetPrime(int min)\n         {\n-            Debug.Assert(min >= 0, \"min less than zero; handle overflow checking before calling HashHelpers\");\n+            if (min < 0)\n+            {\n+                throw new ArgumentException();\n+            }\n \n-            for (int i = 0; i < primes.Length; i++)\n+            foreach (int prime in Primes)\n             {\n-                int prime = primes[i];\n                 if (prime >= min)\n                 {\n                     return prime;\n                 }\n             }\n \n-            // Outside of our predefined table. Compute the hard way. \n-            for (int i = (min | 1); i < Int32.MaxValue; i += 2)\n+            // Outside of our predefined table. Compute the hard way.\n+            for (int i = min | 1; i < int.MaxValue; i += 2)\n             {\n-                if (IsPrime(i))\n+                if (IsPrime(i) && ((i - 1) % HashPrime != 0))\n                 {\n                     return i;\n                 }\n             }\n-            return min;\n-        }\n \n-        internal static int GetMinPrime()\n-        {\n-            return primes[0];\n+            return min;\n         }\n \n         // Returns size of hashtable to grow to.\n-        internal static int ExpandPrime(int oldSize)\n+        public static int ExpandPrime(int oldSize)\n         {\n             int newSize = 2 * oldSize;\n \n-            // Allow the hashtables to grow to maximum possible size (~2G elements) before encoutering capacity overflow.\n+            // Allow the hashtables to grow to maximum possible size (~2G elements) before encountering capacity overflow.\n             // Note that this check works even when _items.Length overflowed thanks to the (uint) cast\n-            if ((uint)newSize > MaxPrimeArrayLength)\n+            if ((uint)newSize > MaxPrimeArrayLength && oldSize < MaxPrimeArrayLength)\n             {\n+                Debug.Assert(GetPrime(MaxPrimeArrayLength) == MaxPrimeArrayLength, \"Invalid MaxPrimeArrayLength\");\n                 return MaxPrimeArrayLength;\n             }\n \n             return GetPrime(newSize);\n         }\n \n-        // This is the maximum prime smaller than Array.MaxArrayLength\n-        internal const int MaxPrimeArrayLength = 0x7FEFFFFD;\n+        /// <summary>Returns approximate reciprocal of the divisor: ceil(2**64 / divisor).</summary>\n+        /// <remarks>This should only be used on 64-bit.</remarks>",
              "author": {
                "login": "stephentoub"
              }
            }
          ]
        }
      }
    ]
  }
}