{
  "number": 6786,
  "title": "Increase ProjectRootElementCache MRU cache",
  "body": "The average imports/project in a recent OrchardCore solution\r\n(primarily ASP.NET Core) is 83, so one project can by itself\r\nevict stuff from the old cache of size 50.\r\n\r\nThere are likely further improvements to be made in this area\r\n(some ideas in #6715), but increasing the size to 200 seems to\r\nbe a [significant improvement with an extremely small change](https://github.com/dotnet/msbuild/issues/6715#issuecomment-905788648).\r\n",
  "state": "MERGED",
  "createdAt": "2021-08-26T13:55:24Z",
  "updatedAt": "2021-12-30T17:58:11Z",
  "closedAt": "2021-09-07T21:52:42Z",
  "mergedAt": "2021-09-07T21:52:42Z",
  "additions": 18,
  "deletions": 17,
  "changedFiles": 1,
  "headRefName": "exp/up-xml-cache-size",
  "isDraft": false,
  "author": {
    "login": "rainersigwald"
  },
  "milestone": {
    "title": "VS 17.0"
  },
  "assignees": {
    "nodes": []
  },
  "labels": [
    "Area: Performance",
    "merge-when-branch-open"
  ],
  "commits": {
    "nodes": [
      {
        "commit": {
          "oid": "730dd7edf5e3ed3986e5662fdba3f8a6df4864f9",
          "message": "Increase ProjectRootElementCache MRU cache\n\nThe average imports/project in a recent OrchardCore solution\n(primarily ASP.NET Core) is 83, so one project can by itself\nevict stuff from the old cache of size 50.\n\nThere are likely further improvements to be made in this area\n(some ideas in #6551), but increasing the size to 200 seems to\nbe a significant improvement with an extremely small change.",
          "committedDate": "2021-08-25T20:41:38Z",
          "author": {
            "name": "Rainer Sigwald",
            "email": "raines@microsoft.com"
          }
        }
      },
      {
        "commit": {
          "oid": "5f983e7529f88414fb79c9429ae9d74a2bebedaa",
          "message": "Merge remote-tracking branch 'upstream/main' into exp/up-xml-cache-size",
          "committedDate": "2021-09-01T14:57:44Z",
          "author": {
            "name": "Rainer Sigwald",
            "email": "raines@microsoft.com"
          }
        }
      }
    ]
  },
  "comments": {
    "nodes": [
      {
        "body": "Should we keep the old size for 32 bit? (I have no opinion)",
        "createdAt": "2021-08-26T14:20:10Z",
        "author": {
          "login": "danmoseley"
        }
      },
      {
        "body": "A good question! I think \"no\" because the thrashing would still be bad there and we still have the \"serialize stuff mid-build\" memory load-shedding functionality. Anybody feel strongly otherwise?",
        "createdAt": "2021-08-26T14:35:28Z",
        "author": {
          "login": "rainersigwald"
        }
      },
      {
        "body": "I agree with the above. `MSBUILDPROJECTROOTELEMENTCACHESIZE` can still be used to override the default value in the unlikely case that the change breaks someone.",
        "createdAt": "2021-08-31T13:01:17Z",
        "author": {
          "login": "ladipro"
        }
      },
      {
        "body": "Internal perf checks are being pretty cranky and I'm still waiting on them before undrafting this:\r\n\r\nhttps://dev.azure.com/devdiv/DevDiv/_git/VS/pullrequest/346941",
        "createdAt": "2021-08-31T14:16:00Z",
        "author": {
          "login": "rainersigwald"
        }
      },
      {
        "body": "Flakiness continues for internal Perf DDRITs but I'm going to go ahead and undraft this anyway.",
        "createdAt": "2021-09-03T16:12:21Z",
        "author": {
          "login": "rainersigwald"
        }
      },
      {
        "body": "Just noting that the searching that happens on import in here is O(n) scan of a linked list. You might want to keep an eye out for if that shows up in profiles now. I'm guessing not, especially since most builds won't approach 200.",
        "createdAt": "2021-09-03T17:42:56Z",
        "author": {
          "login": "danmoseley"
        }
      },
      {
        "body": "> Just noting that the searching that happens on import in here is O(n) scan of a linked list. You might want to keep an eye out for if that shows up in profiles now. I'm guessing not, especially since most builds won't approach 200.\r\n\r\nI talked about this with @rokonec and he didn't observe any problems, but we will keep an eye out. I think a more extensive fix to #6715 will be able to alleviate both.",
        "createdAt": "2021-09-07T18:46:56Z",
        "author": {
          "login": "rainersigwald"
        }
      },
      {
        "body": "Maybe a dumb question, but why keep it as a LinkedList at all? When we're adding something to the cache, we have to check equality for everything in the cache. I have trouble imagining that's faster than a single lookup in a HashSet, even if the cache only has ~30 items in it. It would also simplify our logic somewhat, since we could just add to it and assume any duplication is taken care of. We can optionally decide if we want to keep the max size, though I don't think that'll be a big deal if we don't expect there to be 200 items anyway. I don't see anywhere we really use the order.\r\n\r\nEdit: We use the order to figure out which to evict if we hit the maximum number of things in the cache. That seems reasonable, but I'm not convinced it's really helpful if the cache is still bigger than we really expect it to need to be...",
        "createdAt": "2021-12-30T00:57:40Z",
        "author": {
          "login": "Forgind"
        }
      },
      {
        "body": ">  I'm not convinced it's really helpful if the cache is still bigger than we really expect it to need to be...\r\n\r\nThe typical upper bound on reused imported files is surely below 200, but that has little bearing on how many files the cache will encounter. AFAICR, there is generally one ProjectRootElementCache per process/app domain, so when you build a large tree, then the cache will reach whatever limit you set (which is OK) and then all subsequent project files will be pushed into the cache as they're encountered, and it's important that those are evicted first when more files come in.\r\n\r\nFor example, when building dotnet/runtime src\\libraries, it will load 856 files, probably only 50 are reused and those must not drop from the cache. To achieve that you need some kind of ordering, which was achieved by using a LinkedList and boosting.",
        "createdAt": "2021-12-30T03:35:37Z",
        "author": {
          "login": "danmoseley"
        }
      },
      {
        "body": "Gotcha. A HashSet with no max would probably still perform ok from a time perspective but would keep a lot of extra stuff. If I were to recommend a data structure that maintains orderings but also provides fast lookups/removes and, even better, can be optimized to put recently touched things near the top, I'd recommend a treap (with some kind of time stamp for the heap invariant) or a splay tree. Almost certainly overkill, but I'd be happy to implement one of those for this case if you think it would help \ud83d\ude42",
        "createdAt": "2021-12-30T04:52:00Z",
        "author": {
          "login": "Forgind"
        }
      },
      {
        "body": "> A HashSet with no max would probably still perform ok from a time perspective but would keep a lot of extra stuff. \r\n\r\nIt's important that MSBuild holds essentially zero state per project otherwise sufficiently large builds would regularly crash (32 bit) or bog down paging (64 bit). That's why we even page out build results to disk [if needed](https://github.com/dotnet/msbuild/blob/2e88dc487e73be1ed29a9b77f063250e42bfed73/src/Build/BackEnd/Components/BuildRequestEngine/BuildRequestEngine.cs#L834)\r\n\r\nYes, you're right there may be better data structures to achieve these semantics. \ud83d\ude04 ",
        "createdAt": "2021-12-30T17:57:53Z",
        "author": {
          "login": "danmoseley"
        }
      }
    ]
  },
  "reviewThreads": {
    "nodes": []
  }
}