diff --git a/documentation/specs/proposed/evaluation-perf.md b/documentation/specs/proposed/evaluation-perf.md
index 3a44e42fa53..22ea253c93d 100644
--- a/documentation/specs/proposed/evaluation-perf.md
+++ b/documentation/specs/proposed/evaluation-perf.md
@@ -2,18 +2,14 @@
 In the current effort to improve performance of MSBuild, we identified evaluation as one of the focus areas of this effort. Evaluation is the first step when loading or building, and it determines references, how projects are connected and what needs to be build. Because of this it runs in every MSBuild scenario, from solution load and design-time builds in Visual Studio, to up-to-date builds or full builds in VS or on the command line.
 
 ## Description
-Current performance state of evaluation is mostly unkown, as it is not measured in any ways by the team. As such, we are unsure which specific areas can be improve. The investigation about this is necessary so we can identify weaknesses, and possible fixes.
-
- - We could do profiling
- - Jit compilation of MSBuild itself. 
- - We could cache at eval
-
-Constraint - needs to work as it does today, but faster. We may be able to break some edge cases.
+Current performance state of evaluation is mostly unkown, we have a few measures but no easy way of accessing and assessing them. As such, we are unsure which specific areas can be improve. 
 
 ## Goals and Motivation
 We are trying to make evaluation phase of the build more performant, since it is almost always executed any performance gain becomes noticeable. A performant evaluation phase would decrease build times in general, in CI cases it frees up resources, and in individual cases it can increase dev-loop performance by making up-to-date and incremental builds go faster.
 
-In this moment we are still in investigation phase, the obejective is to add code markers, so we can idetentify low hanging fixes, and improvement areas when testing builds within PerfStar.
+In this moment we are still in investigation phase, the objective is to make the markers we have in code more accessible to the team, so we can idetentify low hanging fixes, and improvement areas when testing builds within PerfStar.
+
+Constraint - needs to work as it does today, but faster. We may be able to break some edge cases.
 
 ## Risks
 One of the big risks is accidentally changing the current behaviour of evaluation. One of the constraints of improvement is that evaluation has the same behavior, with the exception of edge cases where we can sometimes change it.
diff --git a/documentation/specs/proposed/perfStar.md b/documentation/specs/proposed/perfStar.md
index 5d9a6a24d6e..dffb0343aee 100644
--- a/documentation/specs/proposed/perfStar.md
+++ b/documentation/specs/proposed/perfStar.md
@@ -1,14 +1,16 @@
 # PerfStar
-PerfStar is a performance tracking and investigation tool for MSBuild. PerfStar infrastructure captures performance measurements of main MSBuild branch on schedule and allows us to request experimental runs and collect performance of the new changes. The first version of this project is being finalized, with some fixes necessary to run it automatically and according to prerequisites.
+PerfStar is a performance tracking and investigation tool for MSBuild. PerfStar infrastructure captures performance measurements of the `main` MSBuild branch on a schedule and allows us to request experimental runs and collect performance data for proposed changes. The first version of this project is being finalized, with some fixes necessary to run it automatically and according to prerequisites.
 
 ## Goals and Motivation
-MSBuild currently does not have a lot of performance data outside of Visual Studio performance tracking, which has a lot of variables that are beyond the team's control. PerfStar enables us to measure our performance without interference of elements that the team does not own. As such, we can measure the performance of in-development features and how it will impact build times, as well as have concrete numbers when working on performance improvement tasks.
+MSBuild currently does not have a lot of performance data outside of Visual Studio performance tracking, which has a lot of variables that are beyond the team's control. PerfStar enables us to measure our performance with less interference of elements that the team does not own. As such, we can measure the performance of in-development features and how it will impact build times, as well as have concrete numbers when working on performance improvement tasks.
 
 ## Impact
-Perfstar's impact is focused on the team. We will be able to track performance with concrete numbers. Because of that the team will be able to take more informed decisions about taking performance improvement work, as well as future and implementation of new features.
+Perfstar's impact is focused on the team. We will be able to track performance with concrete numbers. Because of that the team will be able to take more informed decisions about performance improvement work, as well as implementation of new features. In turn, those decisions will accrue value to users via higher build performance.
 
 ## Risks
-The risks associated with our dependencies is about Crank, which is owned by the ASP.NET team and we use it to help us with machine setup to run the performance tests. 
+The risks associated with our dependencies is about Crank, which is owned by the ASP.NET team and we use it to help us with machine setup to run the performance tests.
+
+PerfStar also runs as a service. One that the mostly the team uses, but it is a service and carry the same risks as any other service product. Including possible downtime, maintanance, and some security areas.
 
 ## Plan
 Investiment for .NET 10:
@@ -16,18 +18,18 @@ Investiment for .NET 10:
     - Around 1 dev week.
 2. The PowerBI reporting is working and updating the new information
    - Around 2 dev weeks.
-3. New performance tests for new features, and writting docs on how to write those tests. Next feature planned for tests: BuildCheck.
+3. New performance tests for new features, and writing docs on how to write those tests. Next feature planned for tests: BuildCheck.
    - Around 3 dev days per feature.
 4. Analyze stability of performance tests, and fix any noise found. This will be done through multiple iterations of the same test in the same machine, as well as updating the PowerBI report to handle the new data.
    - Around 2 dev weeks.
-5. Add more tests using `msbuild.exe` for build instead of `dotnet build`.
+5. Add more tests using `msbuild.exe` for build in addition to `dotnet build`.
    - Around 1 dev week.
 6. Timeboxed collection of feedback from our team, as well as performance investigations that can derive from those.
    - 1 - 2 dev month depending on feedback and requests for improvement from the team.
 7. Add more test cases. For example, build time with different verbosity levels.
    - Around 1 dev week.
 
-There are more improvements form PerfStar, but these are not established for .NET 10 yet as they depend on the team's feedback to PerfStar.
+There are more improvements form PerfStar, but these are not planned for .NET 10 as they depend on the team's feedback to PerfStar.
 1. Add more measurements, like dotnet counter tool.
    - Around 3 dev weeks.
 2. Trace collection when specific features are turned on for the test.
