diff --git a/documentation/specs/proposed/BuildCheck-Architecture.md b/documentation/specs/proposed/BuildCheck-Architecture.md
index 0b2921c1294..9cf0d0c2290 100644
--- a/documentation/specs/proposed/BuildCheck-Architecture.md
+++ b/documentation/specs/proposed/BuildCheck-Architecture.md
@@ -26,6 +26,8 @@ The major source of data for BuildCheck will be the `BuildEventArgs` data - as i
 
 BuildCheck can source this data either offline from the binlog, or as a plugged logger during the live build execution. Choice was made to support both modes.
 
+The actuall OM exposed to users will be translating/mapping/proxying the underlying MSBuild OM snd hence the implementation details and actual extent of the data (whether internal or public) will be hidden.
+
 ## Execution Modes
 
 **Replay Mode** - so that users can choose to perform analyses post build, without impacting the performance of the build. And so that some level of analysis can be run on artifacts from builds produced by older versions of MSBuild.
@@ -46,10 +48,10 @@ We want to get some benefits (mostly inbox analyzers agility) from hosting Build
 
 How we'll internally handle the distributed model:
 * Each node will have just a single instance of infrastructure (`IBuildCheckManager`) available (registered via the MSBuild DI - `IBuildComponentHost`). This applies to a entrypoint node with inproc worker node as well.
-* Entrypoint node will have an MSBuild `ILogger` registered that will enable funneling data from worker nodes BuildChecks to the entrypoint node BuildCheck - namely:
-    * Acquisition module will be able to communicated to the entrypoint node that particular analyzer should be loaded and instantiated
-    * Tracing module will be able to send partitioned stats and aggregate them together
-    * Theoretical execution-data-only sourcing inbox analyzer will be able to aggregate data from the whole build context (again - we should use this only for agility purposes, but shoot for analyzer that needs presence only in entrypoint node).
+* Entrypoint node will have an MSBuild `ILogger` registered that will enable communicating information from worker nodes BuildCheck module to the entrypoint node BuildCheck module - namely:
+    * Acquisition module from worker node will be able to communicated to the entrypoint node that it encountered `PackageReference` for particular analyzer and that it should be loaded and instantiated in the main node.
+    * Tracing module will be able to send perf stats from current worker node and aggregate al of those together in the main node.
+    * Theoretical execution-data-only sourcing inbox analyzer will be able to aggregate data from the whole build context (again - we should use this only for agility purposes, but shoot for analyzer that needs presence only in entrypoint node). The way to do that can be via being present in all worker nodes, sending a specific type of 'in progress result' BuildEventArgs and aggreggating those intermediary results in the single instance running in the main node.
 * Apart from the scenarios above - the BuildCheck infrastructure modules in individual nodes should be able to function independently (namely - load the inbox analyzers that should live in nodes; send the analyzers reports via logging infrastructure; load user configuration from `.editorconfig` and decide on need to enable/disable/configure particular analyzers).
 * Communication from main to worker node between BuildCheck infra modules is not planned.
 
@@ -58,7 +60,8 @@ How we'll internally handle the distributed model:
 Planned model:
 * Analyzers factories get registered with the BuildCheck infrastructure (`BuildCheckManager`)
     * For inbox analyzers - this happens on startup.
-    * For custom analyzers - this happens on connecting `ILogger` instance in entrypoint node receives acquistion event (`BuildCheckAcquisitionEventArgs`).
+    * For custom analyzers - this happens on connecting `ILogger` instance in entrypoint node receives acquistion event (`BuildCheckAcquisitionEventArgs`). This event is being sent by worker node as soon as it hits a special marker (a magic property function call) during early evaluation. Loading is not porcessed by worker node as currently we want custom analyzers only in the main node (as they will be only given data proxied from BuildEventArgs).
+    The `BuildCheckAcquisitionEventArgs` should be sent prior `ProjectEvaluationStartedEventArgs` (buffering will need to take place), or main node will need to replay some initial data after custom analyzer is registered.
 * `BuildCheckManager` receives info about new project starting to be build
     * On entrypoint node the information is sourced from `ProjectEvaluationStartedEventArgs`
     * On worker node this is received from `RequestBuilder.BuildProject`
@@ -68,6 +71,8 @@ Planned model:
 * `BuildCheckManager` instantiates all newly enabled analyzers and updates configuration for all allready instantiated analyzers.
 * At that point of time analyzers are prepared for receiving data and performing their work. MSBuild will start calling `BuildCheckManager` callbacks (mostly pumping `BuildEventArgs`), passed data will be transalted into BuildCheck OM and passed to analyzers.
 * Analyzers may decide to report results of their findings (via `BuildCopDataContext.ReportResult`), the infrastructure will then perform post-processing (filter out reports for `Rule`s that are disabled, set the severity based on configuration) and send the result via the standard MSBuild logging infrastructure.
+* Analysis result might hence be reported after project's final `ProjectFinishedEventArgs`
+* Final status of the build should not be reported (and `BuildFinishedEventArgs` logged) until all analyzers are done processing and their results are accounted for.
 
 # Configuration
 
